{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traffic Light Classifier - Evaluation\n",
    "\n",
    "Notebook to evaluate the pretrained models in https://github.com/ThomasHenckel/CarND-Capstone/tree/master/Traffic_Light_Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/the_workspace/models/research/object_detection/utils/visualization_utils.py:25: UserWarning: matplotlib.pyplot as already been imported, this call will have no effect.\n",
      "  import matplotlib; matplotlib.use('Agg')  # pylint: disable=multiple-statements\n"
     ]
    }
   ],
   "source": [
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to use converted model: `models/converted_to_TFv14/ssd_mobilenet/frozen_inference_graph.pb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_DIR = os.path.join('..', 'models', 'exported') #'exported')\n",
    "model_file = 'ssd_mobilenet/frozen_inference_graph.pb' #'ssd_mobilenet/frozen_inference_graph.pb'\n",
    "\n",
    "MODEL_PATH = os.path.join(MODELS_DIR, model_file)\n",
    "LABELS_MAP_PATH = os.path.join('..', 'config', 'labels_map.pbtxt') #PATH_TO_LABELS = 'labels_map.pbtxt'\n",
    "\n",
    "NUM_CLASSES = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loadig label map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {'id': 1, 'name': 'Green'}, 2: {'id': 2, 'name': 'Yellow'}, 3: {'id': 3, 'name': 'Red'}}\n"
     ]
    }
   ],
   "source": [
    "label_map = label_map_util.load_labelmap(LABELS_MAP_PATH)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "print(category_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape(\n",
    "        (im_height, im_width, 3)).astype(np.uint8)\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "\n",
    "    with tf.gfile.GFile(MODEL_PATH, 'rb') as fid:\n",
    "        \n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../test_images/190304_StAn_Udacity_Real_Traffic_Lights_Training/*.jpg\n",
      "Length of test images: 0\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = os.path.join('..', 'test_images/190304_StAn_Udacity_Real_Traffic_Lights_Training') \n",
    "\n",
    "print(os.path.join(DATA_DIR, '*.jpg'))\n",
    "DATA_PATHS = glob(os.path.join(DATA_DIR, '*.jpg'))\n",
    "print(\"Length of test images:\", len(DATA_PATHS))\n",
    "\n",
    "# Size, in inches, of the output images. (original size: 350, 280)\n",
    "IMAGE_SIZE = (10, 8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350, 280)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path_1 = os.path.join('..', 'test_images', 'uda_loop_r.jpg')\n",
    "image_1 = Image.open(image_path_1)\n",
    "image_1.size\n",
    "\n",
    "image_path_2 = os.path.join('..', 'test_images', 'sim_y.jpg')\n",
    "image_2 = Image.open(image_path_1)\n",
    "image_2.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing classification in Yellow Lights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/d/the_workspace/SelfDrivingCar/Traffic_Light_Detection/notebooks\n",
      "Length of test images: 0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# Testing Yellow Lights:\n",
    "\n",
    "DATA_DIR = os.path.join('..', 'test_images/1190304_StAn_Udacity_Simulator_Traffic_Lights_Training') \n",
    "DATA_PATHS = sorted(glob(os.path.join(DATA_DIR, '*.png')))\n",
    "print(\"Length of test images:\", len(DATA_PATHS))\n",
    "\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        # Definite input and output Tensors for detection_graph\n",
    "        image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "        \n",
    "        # Each box represents a part of the image where a particular object was detected.\n",
    "        detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "        \n",
    "        # Each score represent how level of confidence for each of the objects.\n",
    "        # Score is shown on the result image, together with the class label.\n",
    "        detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "        detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "        num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "        for image_path in DATA_PATHS:\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            # the array based representation of the image will be used later in order to prepare the\n",
    "            # result image with boxes and labels on it.\n",
    "            image_np = load_image_into_numpy_array(image)\n",
    "            # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "\n",
    "            time0 = time.time()\n",
    "\n",
    "            # Actual detection.\n",
    "            (boxes, scores, classes, num) = sess.run(\n",
    "              [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "              feed_dict={image_tensor: image_np_expanded})\n",
    "\n",
    "            time1 = time.time()\n",
    "\n",
    "            boxes = np.squeeze(boxes)\n",
    "            scores = np.squeeze(scores)\n",
    "            classes = np.squeeze(classes).astype(np.int32)\n",
    "            \n",
    "            # Visualization of the results of a detection.\n",
    "            vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np, boxes, classes, scores,\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                line_thickness=4)\n",
    "            \n",
    "            print(\"Image name\", image_path)\n",
    "            plt.figure(figsize=IMAGE_SIZE)\n",
    "            plt.imshow(image_np)\n",
    "            plt.show()\n",
    "            #im = Image.fromarray(image_np)\n",
    "            #im.save(\"../test_images_result/190304_StAn_Udacity_Real_Traffic_Lights_Training/\"+image_path.split('/')[-1], \"JPEG\", quality=80, optimize=True, progressive=True)\n",
    "\n",
    "            min_score_thresh = .30\n",
    "            for i in range(boxes.shape[0]):\n",
    "                if scores is None or scores[i] > min_score_thresh:\n",
    "\n",
    "                    class_name = category_index[classes[i]]['name']\n",
    "                    print('{}'.format(class_name), scores[i])\n",
    "                    \n",
    "                    fx =  0.97428  #1345.200806\n",
    "                    fy =  1.73205  #1353.838257\n",
    "                    perceived_width_x = (boxes[i][3] - boxes[i][1]) * 800\n",
    "                    perceived_width_y = (boxes[i][2] - boxes[i][0]) * 600\n",
    "\n",
    "                    # ymin, xmin, ymax, xmax = box\n",
    "                    # depth_prime = (width_real * focal) / perceived_width\n",
    "                    perceived_depth_x = ((.1 * fx) / perceived_width_x)\n",
    "                    perceived_depth_y = ((.3 * fy) / perceived_width_y )\n",
    "\n",
    "                    estimated_distance = round((perceived_depth_x + perceived_depth_y) / 2)\n",
    "                    print(\"Distance (metres)\", estimated_distance)\n",
    "                    print(\"Time in milliseconds\", (time1 - time0) * 1000, \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
